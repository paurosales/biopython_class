{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2007 by Michiel de Hoon.  All rights reserved.\n",
    "# This code is part of the Biopython distribution and governed by its\n",
    "# license.  Please see the LICENSE file that should have been included\n",
    "# as part of this package.\n",
    "\"\"\"Code to work with the sprotXX.dat file from SwissProt.\n",
    "\n",
    "https://web.expasy.org/docs/userman.html\n",
    "\n",
    "Classes:\n",
    " - Record             Holds SwissProt data.\n",
    " - Reference          Holds reference data from a SwissProt record.\n",
    "\n",
    "Functions:\n",
    " - read               Read one SwissProt record\n",
    " - parse              Read multiple SwissProt records\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import io\n",
    "\n",
    "from Bio.SeqFeature import (\n",
    "    SeqFeature,\n",
    "    FeatureLocation,\n",
    "    ExactPosition,\n",
    "    BeforePosition,\n",
    "    AfterPosition,\n",
    "    UncertainPosition,\n",
    "    UnknownPosition,\n",
    ")\n",
    "\n",
    "\n",
    "class SwissProtParserError(ValueError):\n",
    "    \"\"\"An error occurred while parsing a SwissProt file.\"\"\"\n",
    "\n",
    "    def __init__(self, *args, line=None):\n",
    "        \"\"\"Create a SwissProtParserError object with the offending line.\"\"\"\n",
    "        super().__init__(*args)\n",
    "        self.line = line\n",
    "\n",
    "\n",
    "class Record:\n",
    "    \"\"\"Holds information from a SwissProt record.\n",
    "\n",
    "    Attributes:\n",
    "     - entry_name        Name of this entry, e.g. RL1_ECOLI.\n",
    "     - data_class        Either 'STANDARD' or 'PRELIMINARY'.\n",
    "     - molecule_type     Type of molecule, 'PRT',\n",
    "     - sequence_length   Number of residues.\n",
    "     - accessions        List of the accession numbers, e.g. ['P00321']\n",
    "     - created           A tuple of (date, release).\n",
    "     - sequence_update   A tuple of (date, release).\n",
    "     - annotation_update A tuple of (date, release).\n",
    "     - description       Free-format description.\n",
    "     - gene_name         Gene name.  See userman.txt for description.\n",
    "     - organism          The source of the sequence.\n",
    "     - organelle         The origin of the sequence.\n",
    "     - organism_classification  The taxonomy classification.  List of strings.\n",
    "       (http://www.ncbi.nlm.nih.gov/Taxonomy/)\n",
    "     - taxonomy_id       A list of NCBI taxonomy id's.\n",
    "     - host_organism     A list of names of the hosts of a virus, if any.\n",
    "     - host_taxonomy_id  A list of NCBI taxonomy id's of the hosts, if any.\n",
    "     - references        List of Reference objects.\n",
    "     - comments          List of strings.\n",
    "     - cross_references  List of tuples (db, id1[, id2][, id3]).  See the docs.\n",
    "     - keywords          List of the keywords.\n",
    "     - features          List of tuples (key name, from, to, description).\n",
    "       from and to can be either integers for the residue\n",
    "       numbers, '<', '>', or '?'\n",
    "     - protein_existence Numerical value describing the evidence for the existence of the protein.\n",
    "     - seqinfo           tuple of (length, molecular weight, CRC32 value)\n",
    "     - sequence          The sequence.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from Bio import SwissProt\n",
    "    >>> example_filename = \"SwissProt/sp008\"\n",
    "    >>> with open(example_filename) as handle:\n",
    "    ...     records = SwissProt.parse(handle)\n",
    "    ...     for record in records:\n",
    "    ...         print(record.entry_name)\n",
    "    ...         print(\",\".join(record.accessions))\n",
    "    ...         print(record.keywords)\n",
    "    ...         print(repr(record.organism))\n",
    "    ...         print(record.sequence[:20] + \"...\")\n",
    "    ...\n",
    "    1A02_HUMAN\n",
    "    P01892,P06338,P30514,P30444,P30445,P30446,Q29680,Q29899,Q95352,Q29837,Q95380\n",
    "    ['MHC I', 'Transmembrane', 'Glycoprotein', 'Signal', 'Polymorphism', '3D-structure']\n",
    "    'Homo sapiens (Human).'\n",
    "    MAVMAPRTLVLLLSGALALT...\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the class.\"\"\"\n",
    "        self.entry_name = None\n",
    "        self.data_class = None\n",
    "        self.molecule_type = None\n",
    "        self.sequence_length = None\n",
    "\n",
    "        self.accessions = []\n",
    "        self.created = None\n",
    "        self.sequence_update = None\n",
    "        self.annotation_update = None\n",
    "\n",
    "        self.description = []\n",
    "        self.gene_name = \"\"\n",
    "        self.organism = []\n",
    "        self.organelle = \"\"\n",
    "        self.organism_classification = []\n",
    "        self.taxonomy_id = []\n",
    "        self.host_organism = []\n",
    "        self.host_taxonomy_id = []\n",
    "        self.references = []\n",
    "        self.comments = []\n",
    "        self.cross_references = []\n",
    "        self.keywords = []\n",
    "        self.features = []\n",
    "        self.protein_existence = \"\"\n",
    "\n",
    "        self.seqinfo = None\n",
    "        self.sequence = \"\"\n",
    "\n",
    "\n",
    "class Reference:\n",
    "    \"\"\"Holds information from one reference in a SwissProt entry.\n",
    "\n",
    "    Attributes:\n",
    "     - number      Number of reference in an entry.\n",
    "     - evidence    Evidence code.  List of strings.\n",
    "     - positions   Describes extent of work.  List of strings.\n",
    "     - comments    Comments.  List of (token, text).\n",
    "     - references  References.  List of (dbname, identifier).\n",
    "     - authors     The authors of the work.\n",
    "     - title       Title of the work.\n",
    "     - location    A citation for the work.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the class.\"\"\"\n",
    "        self.number = None\n",
    "        self.positions = []\n",
    "        self.comments = []\n",
    "        self.references = []\n",
    "        self.authors = []\n",
    "        self.title = []\n",
    "        self.location = []\n",
    "\n",
    "\n",
    "class FeatureTable(SeqFeature):\n",
    "    \"\"\"Stores feature annotations for specific regions of the sequence.\n",
    "\n",
    "    This is a subclass of SeqFeature, defined in Bio.SeqFeature, where the\n",
    "    attributes are used as follows:\n",
    "\n",
    "     - ``location``: location of the feature on the canonical or isoform\n",
    "       sequence; the location is stored as an instance of FeatureLocation,\n",
    "       defined in Bio.SeqFeature, with the ref attribute set to the isoform\n",
    "       ID referring to the canonical or isoform sequence on which the feature\n",
    "       is defined\n",
    "     - ``id``: unique and stable identifier (FTId), only provided for features\n",
    "       belonging to the types CARBOHYD, CHAIN, PEPTIDE, PROPEP, VARIANT, or\n",
    "       VAR_SEQ\n",
    "     - ``type``: indicates the type of feature, as defined by the UniProt\n",
    "       Knowledgebase documentation:\n",
    "\n",
    "        - ACT_SITE: amino acid(s) involved in the activity of an enzyme\n",
    "        - BINDING:  binding site for any chemical group\n",
    "        - CARBOHYD: glycosylation site; an FTId identifier to the GlyConnect\n",
    "          database is provided if annotated there\n",
    "        - CA_BIND:  calcium-binding region\n",
    "        - CHAIN:    polypeptide chain in the mature protein\n",
    "        - COILED:   coiled-coil region\n",
    "        - COMPBIAS: compositionally biased region\n",
    "        - CONFLICT: different sources report differing sequences\n",
    "        - CROSSLNK: posttransationally formed amino acid bond\n",
    "        - DISULFID: disulfide bond\n",
    "        - DNA_BIND: DNA-binding region\n",
    "        - DOMAIN:   domain, defined as a specific combination of secondary\n",
    "          structures organized into a characteristic three-dimensional\n",
    "          structure or fold\n",
    "        - INIT_MET: initiator methionine\n",
    "        - INTRAMEM: region located in a membrane without crossing it\n",
    "        - HELIX:    alpha-, 3(10)-, or pi-helix secondary structure\n",
    "        - LIPID:    covalent binding of a lipid moiety\n",
    "        - METAL:    binding site for a metal ion\n",
    "        - MOD_RES:  posttranslational modification (PTM) of a residue,\n",
    "          annotated by the controlled vocabulary defined by the ptmlist.txt\n",
    "          document on the UniProt website\n",
    "        - MOTIF:    short sequence motif of biological interest\n",
    "        - MUTAGEN:  site experimentally altered by mutagenesis\n",
    "        - NON_CONS: non-consecutive residues\n",
    "        - NON_STD:  non-standard amino acid\n",
    "        - NON_TER:  the residue at an extremity of the sequence is not the\n",
    "          terminal residue\n",
    "        - NP_BIND:  nucleotide phosphate-binding region\n",
    "        - PEPTIDE:  released active mature polypeptide\n",
    "        - PROPEP:   any processed propeptide\n",
    "        - REGION:   region of interest in the sequence\n",
    "        - REPEAT:   internal sequence repetition\n",
    "        - SIGNAL:   signal sequence (prepeptide)\n",
    "        - SITE:     amino-acid site of interest not represented by another\n",
    "          feature key\n",
    "        - STRAND:   beta-strand secondary structure; either a hydrogen-bonded\n",
    "          extended beta strand or a residue in an isolated beta-bridge\n",
    "        - TOPO_DOM: topological domain\n",
    "        - TRANSIT:  transit peptide (mitochondrion, chloroplast, thylakoid,\n",
    "          cyanelle, peroxisome, etc.)\n",
    "        - TRANSMEM: transmembrane region\n",
    "        - TURN:     H-bonded turn (3-, 4-, or 5-turn)\n",
    "        - UNSURE:   uncertainties in the sequence\n",
    "        - VARIANT:  sequence variant; an FTId is provided for protein sequence\n",
    "          variants of Hominidae (great apes and humans)\n",
    "        - VAR_SEQ:  sequence variant produced by alternative splicing,\n",
    "          alternative promoter usage, alternative initiation, or ribosomal\n",
    "          frameshifting\n",
    "        - ZN_FING:  zinc finger region\n",
    "\n",
    "     - qualifiers   A dictionary of additional information, which may include\n",
    "       the feature evidence and free-text notes. While SwissProt includes the\n",
    "       feature identifier code (FTId) as a qualifier, it is stored as the\n",
    "       attribute ID of the FeatureTable object.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def parse(source):\n",
    "    \"\"\"Read multiple SwissProt records from file.\n",
    "\n",
    "    Argument source is a file-like object or a path to a file.\n",
    "\n",
    "    Returns a generator object which yields Bio.SwissProt.Record() objects.\n",
    "    \"\"\"\n",
    "    handle = _open(source)\n",
    "    try:\n",
    "        while True:\n",
    "            record = _read(handle)\n",
    "            if not record:\n",
    "                return\n",
    "            yield record\n",
    "    finally:\n",
    "        if handle is not source:\n",
    "            handle.close()\n",
    "\n",
    "\n",
    "def read(source):\n",
    "    \"\"\"Read one SwissProt record from file.\n",
    "\n",
    "    Argument source is a file-like object or a path to a file.\n",
    "\n",
    "    Returns a Record() object.\n",
    "    \"\"\"\n",
    "    handle = _open(source)\n",
    "    try:\n",
    "        record = _read(handle)\n",
    "        if not record:\n",
    "            raise ValueError(\"No SwissProt record found\")\n",
    "        # We should have reached the end of the record by now.\n",
    "        # Try to read one more line to be sure:\n",
    "        try:\n",
    "            next(handle)\n",
    "        except StopIteration:\n",
    "            return record\n",
    "        raise ValueError(\"More than one SwissProt record found\")\n",
    "    finally:\n",
    "        if handle is not source:\n",
    "            handle.close()\n",
    "\n",
    "\n",
    "# Everything below is considered private\n",
    "\n",
    "\n",
    "def _open(source):\n",
    "    try:\n",
    "        handle = open(source)\n",
    "        return handle\n",
    "    except TypeError:\n",
    "        handle = source\n",
    "        if handle.read(0) == \"\":\n",
    "            # handle is text; assume the encoding is compatible with ASCII\n",
    "            return handle\n",
    "        # handle is binary; SwissProt encoding is always ASCII\n",
    "        return io.TextIOWrapper(handle, encoding=\"ASCII\")\n",
    "\n",
    "\n",
    "def _read(handle):\n",
    "    record = None\n",
    "    unread = \"\"\n",
    "    try:\n",
    "        line = next(handle)\n",
    "    except StopIteration:\n",
    "        return record\n",
    "    key, value = line[:2], line[5:].rstrip()\n",
    "    if key != \"ID\":\n",
    "        raise SwissProtParserError(\"Failed to find ID in first line\", line=line)\n",
    "    record = Record()\n",
    "    _read_id(record, line)\n",
    "    _sequence_lines = []\n",
    "    for line in handle:\n",
    "        key, value = line[:2], line[5:].rstrip()\n",
    "        if unread:\n",
    "            value = unread + \" \" + value\n",
    "            unread = \"\"\n",
    "        if key == \"AC\":\n",
    "            accessions = value.rstrip(\";\").split(\"; \")\n",
    "            record.accessions.extend(accessions)\n",
    "        elif key == \"DT\":\n",
    "            _read_dt(record, line)\n",
    "        elif key == \"DE\":\n",
    "            record.description.append(value.strip())\n",
    "        elif key == \"GN\":\n",
    "            if record.gene_name:\n",
    "                record.gene_name += \" \"\n",
    "            record.gene_name += value\n",
    "        elif key == \"OS\":\n",
    "            record.organism.append(value)\n",
    "        elif key == \"OG\":\n",
    "            record.organelle += line[5:]\n",
    "        elif key == \"OC\":\n",
    "            cols = value.rstrip(\";.\").split(\"; \")\n",
    "            record.organism_classification.extend(cols)\n",
    "        elif key == \"OX\":\n",
    "            _read_ox(record, line)\n",
    "        elif key == \"OH\":\n",
    "            _read_oh(record, line)\n",
    "        elif key == \"RN\":\n",
    "            reference = Reference()\n",
    "            _read_rn(reference, value)\n",
    "            record.references.append(reference)\n",
    "        elif key == \"RP\":\n",
    "            assert record.references, \"RP: missing RN\"\n",
    "            record.references[-1].positions.append(value)\n",
    "        elif key == \"RC\":\n",
    "            assert record.references, \"RC: missing RN\"\n",
    "            reference = record.references[-1]\n",
    "            unread = _read_rc(reference, value)\n",
    "        elif key == \"RX\":\n",
    "            assert record.references, \"RX: missing RN\"\n",
    "            reference = record.references[-1]\n",
    "            _read_rx(reference, value)\n",
    "        elif key == \"RL\":\n",
    "            assert record.references, \"RL: missing RN\"\n",
    "            reference = record.references[-1]\n",
    "            reference.location.append(value)\n",
    "        # In UniProt release 1.12 of 6/21/04, there is a new RG\n",
    "        # (Reference Group) line, which references a group instead of\n",
    "        # an author.  Each block must have at least 1 RA or RG line.\n",
    "        elif key == \"RA\":\n",
    "            assert record.references, \"RA: missing RN\"\n",
    "            reference = record.references[-1]\n",
    "            reference.authors.append(value)\n",
    "        elif key == \"RG\":\n",
    "            assert record.references, \"RG: missing RN\"\n",
    "            reference = record.references[-1]\n",
    "            reference.authors.append(value)\n",
    "        elif key == \"RT\":\n",
    "            assert record.references, \"RT: missing RN\"\n",
    "            reference = record.references[-1]\n",
    "            reference.title.append(value)\n",
    "        elif key == \"CC\":\n",
    "            _read_cc(record, line)\n",
    "        elif key == \"DR\":\n",
    "            _read_dr(record, value)\n",
    "        elif key == \"PE\":\n",
    "            _read_pe(record, value)\n",
    "        elif key == \"KW\":\n",
    "            _read_kw(record, value)\n",
    "        elif key == \"FT\":\n",
    "            _read_ft(record, line)\n",
    "        elif key == \"SQ\":\n",
    "            cols = value.split()\n",
    "            assert len(cols) == 7, \"I don't understand SQ line %s\" % line\n",
    "            # Do more checking here?\n",
    "            record.seqinfo = int(cols[1]), int(cols[3]), cols[5]\n",
    "        elif key == \"  \":\n",
    "            _sequence_lines.append(value.replace(\" \", \"\").rstrip())\n",
    "        elif key == \"//\":\n",
    "            # Join multiline data into one string\n",
    "            record.description = \" \".join(record.description)\n",
    "            record.organism = \" \".join(record.organism)\n",
    "            record.organelle = record.organelle.rstrip()\n",
    "            for reference in record.references:\n",
    "                reference.authors = \" \".join(reference.authors).rstrip(\";\")\n",
    "                if reference.title:\n",
    "                    title = reference.title[0]\n",
    "                    for fragment in reference.title[1:]:\n",
    "                        if not title.endswith(\"-\"):\n",
    "                            title += \" \"\n",
    "                        title += fragment\n",
    "                    title = title.rstrip(\";\")\n",
    "                    if title.startswith('\"') and title.endswith('\"'):\n",
    "                        title = title[1:-1]  # remove quotes\n",
    "                else:\n",
    "                    title = \"\"\n",
    "                reference.title = title\n",
    "                reference.location = \" \".join(reference.location)\n",
    "            record.sequence = \"\".join(_sequence_lines)\n",
    "            return record\n",
    "        elif key == \"**\":\n",
    "            # Do this one last, as it will almost never occur.\n",
    "            # See Bug 2353, some files from the EBI have extra lines\n",
    "            # starting \"**\" (two asterisks/stars).  They appear\n",
    "            # to be unofficial automated annotations. e.g.\n",
    "            # **\n",
    "            # **   #################    INTERNAL SECTION    ##################\n",
    "            # **HA SAM; Annotated by PicoHamap 1.88; MF_01138.1; 09-NOV-2003.\n",
    "            pass\n",
    "        else:\n",
    "            raise SwissProtParserError(\"Unknown keyword '%s' found\" % key, line=line)\n",
    "    if record:\n",
    "        raise ValueError(\"Unexpected end of stream.\")\n",
    "\n",
    "\n",
    "def _read_id(record, line):\n",
    "    cols = line[5:].split()\n",
    "    # Prior to release 51, included with MoleculeType:\n",
    "    # ID   EntryName DataClass; MoleculeType; SequenceLength AA.\n",
    "    #\n",
    "    # Newer files lack the MoleculeType:\n",
    "    # ID   EntryName DataClass; SequenceLength AA.\n",
    "    if len(cols) == 5:\n",
    "        record.entry_name = cols[0]\n",
    "        record.data_class = cols[1].rstrip(\";\")\n",
    "        record.molecule_type = cols[2].rstrip(\";\")\n",
    "        record.sequence_length = int(cols[3])\n",
    "    elif len(cols) == 4:\n",
    "        record.entry_name = cols[0]\n",
    "        record.data_class = cols[1].rstrip(\";\")\n",
    "        record.molecule_type = None\n",
    "        record.sequence_length = int(cols[2])\n",
    "    else:\n",
    "        raise SwissProtParserError(\"ID line has unrecognised format\", line=line)\n",
    "    # check if the data class is one of the allowed values\n",
    "    allowed = (\"STANDARD\", \"PRELIMINARY\", \"IPI\", \"Reviewed\", \"Unreviewed\")\n",
    "    if record.data_class not in allowed:\n",
    "        message = \"Unrecognized data class '%s'\" % record.data_class\n",
    "        raise SwissProtParserError(message, line=line)\n",
    "\n",
    "    # molecule_type should be 'PRT' for PRoTein\n",
    "    # Note that has been removed in recent releases (set to None)\n",
    "    if record.molecule_type not in (None, \"PRT\"):\n",
    "        message = \"Unrecognized molecule type '%s'\" % record.molecule_type\n",
    "        raise SwissProtParserError(message, line=line)\n",
    "\n",
    "\n",
    "def _read_dt(record, line):\n",
    "    value = line[5:]\n",
    "    uprline = value.upper()\n",
    "    cols = value.rstrip().split()\n",
    "    if (\n",
    "        \"CREATED\" in uprline\n",
    "        or \"LAST SEQUENCE UPDATE\" in uprline\n",
    "        or \"LAST ANNOTATION UPDATE\" in uprline\n",
    "    ):\n",
    "        # Old style DT line\n",
    "        # =================\n",
    "        # e.g.\n",
    "        # DT   01-FEB-1995 (Rel. 31, Created)\n",
    "        # DT   01-FEB-1995 (Rel. 31, Last sequence update)\n",
    "        # DT   01-OCT-2000 (Rel. 40, Last annotation update)\n",
    "        #\n",
    "        # or:\n",
    "        # DT   08-JAN-2002 (IPI Human rel. 2.3, Created)\n",
    "        # ...\n",
    "\n",
    "        # find where the version information will be located\n",
    "        # This is needed for when you have cases like IPI where\n",
    "        # the release version is in a different spot:\n",
    "        # DT   08-JAN-2002 (IPI Human rel. 2.3, Created)\n",
    "        uprcols = uprline.split()\n",
    "        rel_index = -1\n",
    "        for index in range(len(uprcols)):\n",
    "            if \"REL.\" in uprcols[index]:\n",
    "                rel_index = index\n",
    "        assert rel_index >= 0, \"Could not find Rel. in DT line: %s\" % line\n",
    "        version_index = rel_index + 1\n",
    "        # get the version information\n",
    "        str_version = cols[version_index].rstrip(\",\")\n",
    "        # no version number\n",
    "        if str_version == \"\":\n",
    "            version = 0\n",
    "        # dot versioned\n",
    "        elif \".\" in str_version:\n",
    "            version = str_version\n",
    "        # integer versioned\n",
    "        else:\n",
    "            version = int(str_version)\n",
    "        date = cols[0]\n",
    "\n",
    "        if \"CREATED\" in uprline:\n",
    "            record.created = date, version\n",
    "        elif \"LAST SEQUENCE UPDATE\" in uprline:\n",
    "            record.sequence_update = date, version\n",
    "        elif \"LAST ANNOTATION UPDATE\" in uprline:\n",
    "            record.annotation_update = date, version\n",
    "        else:\n",
    "            raise SwissProtParserError(\"Unrecognised DT (DaTe) line\", line=line)\n",
    "    elif (\n",
    "        \"INTEGRATED INTO\" in uprline\n",
    "        or \"SEQUENCE VERSION\" in uprline\n",
    "        or \"ENTRY VERSION\" in uprline\n",
    "    ):\n",
    "        # New style DT line\n",
    "        # =================\n",
    "        # As of UniProt Knowledgebase release 7.0 (including\n",
    "        # Swiss-Prot release 49.0 and TrEMBL release 32.0) the\n",
    "        # format of the DT lines and the version information\n",
    "        # in them was changed - the release number was dropped.\n",
    "        #\n",
    "        # For more information see bug 1948 and\n",
    "        # http://ca.expasy.org/sprot/relnotes/sp_news.html#rel7.0\n",
    "        #\n",
    "        # e.g.\n",
    "        # DT   01-JAN-1998, integrated into UniProtKB/Swiss-Prot.\n",
    "        # DT   15-OCT-2001, sequence version 3.\n",
    "        # DT   01-APR-2004, entry version 14.\n",
    "        #\n",
    "        # This is a new style DT line...\n",
    "\n",
    "        # The date should be in string cols[1]\n",
    "        # Get the version number if there is one.\n",
    "        # For the three DT lines above: 0, 3, 14\n",
    "        try:\n",
    "            version = 0\n",
    "            for s in cols[-1].split(\".\"):\n",
    "                if s.isdigit():\n",
    "                    version = int(s)\n",
    "        except ValueError:\n",
    "            version = 0\n",
    "        date = cols[0].rstrip(\",\")\n",
    "\n",
    "        # Re-use the historical property names, even though\n",
    "        # the meaning has changed slighty:\n",
    "        if \"INTEGRATED\" in uprline:\n",
    "            record.created = date, version\n",
    "        elif \"SEQUENCE VERSION\" in uprline:\n",
    "            record.sequence_update = date, version\n",
    "        elif \"ENTRY VERSION\" in uprline:\n",
    "            record.annotation_update = date, version\n",
    "        else:\n",
    "            raise SwissProtParserError(\"Unrecognised DT (DaTe) line\", line=line)\n",
    "    else:\n",
    "        raise SwissProtParserError(\"Failed to parse DT (DaTe) line\", line=line)\n",
    "\n",
    "\n",
    "def _read_ox(record, line):\n",
    "    # The OX line used to be in the simple format:\n",
    "    # OX   DESCRIPTION=ID[, ID]...;\n",
    "    # If there are too many id's to fit onto a line, then the ID's\n",
    "    # continue directly onto the next line, e.g.\n",
    "    # OX   DESCRIPTION=ID[, ID]...\n",
    "    # OX   ID[, ID]...;\n",
    "    # Currently, the description is always \"NCBI_TaxID\".\n",
    "    # To parse this, I need to check to see whether I'm at the\n",
    "    # first line.  If I am, grab the description and make sure\n",
    "    # it's an NCBI ID.  Then, grab all the id's.\n",
    "    #\n",
    "    # As of the 2014-10-01 release, there may be an evidence code, e.g.\n",
    "    # OX   NCBI_TaxID=418404 {ECO:0000313|EMBL:AEX14553.1};\n",
    "    # In the short term, we will ignore any evidence codes:\n",
    "    line = line.split(\"{\")[0]\n",
    "    if record.taxonomy_id:\n",
    "        ids = line[5:].rstrip().rstrip(\";\")\n",
    "    else:\n",
    "        descr, ids = line[5:].rstrip().rstrip(\";\").split(\"=\")\n",
    "        assert descr == \"NCBI_TaxID\", \"Unexpected taxonomy type %s\" % descr\n",
    "    record.taxonomy_id.extend(ids.split(\", \"))\n",
    "\n",
    "\n",
    "def _read_oh(record, line):\n",
    "    # Line type OH (Organism Host) for viral hosts\n",
    "    assert line[5:].startswith(\"NCBI_TaxID=\"), \"Unexpected %s\" % line\n",
    "    line = line[16:].rstrip()\n",
    "    assert line[-1] == \".\" and line.count(\";\") == 1, line\n",
    "    taxid, name = line[:-1].split(\";\")\n",
    "    record.host_taxonomy_id.append(taxid.strip())\n",
    "    record.host_organism.append(name.strip())\n",
    "\n",
    "\n",
    "def _read_rn(reference, rn):\n",
    "    # This used to be a very simple line with a reference number, e.g.\n",
    "    # RN   [1]\n",
    "    # As of the 2014-10-01 release, there may be an evidence code, e.g.\n",
    "    # RN   [1] {ECO:0000313|EMBL:AEX14553.1}\n",
    "    words = rn.split(None, 1)\n",
    "    number = words[0]\n",
    "    assert number.startswith(\"[\") and number.endswith(\"]\"), (\n",
    "        \"Missing brackets %s\" % number\n",
    "    )\n",
    "    reference.number = int(number[1:-1])\n",
    "    if len(words) > 1:\n",
    "        evidence = words[1]\n",
    "        assert evidence.startswith(\"{\") and evidence.endswith(\"}\"), (\n",
    "            \"Missing braces %s\" % evidence\n",
    "        )\n",
    "        reference.evidence = evidence[1:-1].split(\"|\")\n",
    "\n",
    "\n",
    "def _read_rc(reference, value):\n",
    "    cols = value.split(\";\")\n",
    "    if value[-1] == \";\":\n",
    "        unread = \"\"\n",
    "    else:\n",
    "        cols, unread = cols[:-1], cols[-1]\n",
    "    for col in cols:\n",
    "        if not col:  # last column will be the empty string\n",
    "            return\n",
    "        # The token is everything before the first '=' character.\n",
    "        i = col.find(\"=\")\n",
    "        if i >= 0:\n",
    "            token, text = col[:i], col[i + 1 :]\n",
    "            comment = token.lstrip(), text\n",
    "            reference.comments.append(comment)\n",
    "        else:\n",
    "            comment = reference.comments[-1]\n",
    "            comment = \"%s %s\" % (comment, col)\n",
    "            reference.comments[-1] = comment\n",
    "    return unread\n",
    "\n",
    "\n",
    "def _read_rx(reference, value):\n",
    "    # The basic (older?) RX line is of the form:\n",
    "    # RX   MEDLINE; 85132727.\n",
    "    # but there are variants of this that need to be dealt with (see below)\n",
    "\n",
    "    # CLD1_HUMAN in Release 39 and DADR_DIDMA in Release 33\n",
    "    # have extraneous information in the RX line.  Check for\n",
    "    # this and chop it out of the line.\n",
    "    # (noticed by katel@worldpath.net)\n",
    "    value = value.replace(\" [NCBI, ExPASy, Israel, Japan]\", \"\")\n",
    "\n",
    "    # RX lines can also be used of the form\n",
    "    # RX   PubMed=9603189;\n",
    "    # reported by edvard@farmasi.uit.no\n",
    "    # and these can be more complicated like:\n",
    "    # RX   MEDLINE=95385798; PubMed=7656980;\n",
    "    # RX   PubMed=15060122; DOI=10.1136/jmg 2003.012781;\n",
    "    # We look for these cases first and deal with them\n",
    "    warn = False\n",
    "    if \"=\" in value:\n",
    "        cols = value.split(\"; \")\n",
    "        cols = [x.strip() for x in cols]\n",
    "        cols = [x for x in cols if x]\n",
    "        for col in cols:\n",
    "            x = col.split(\"=\")\n",
    "            if len(x) != 2 or x == (\"DOI\", \"DOI\"):\n",
    "                warn = True\n",
    "                break\n",
    "            assert len(x) == 2, \"I don't understand RX line %s\" % value\n",
    "            reference.references.append((x[0], x[1].rstrip(\";\")))\n",
    "    # otherwise we assume we have the type 'RX   MEDLINE; 85132727.'\n",
    "    else:\n",
    "        cols = value.split(\"; \")\n",
    "        # normally we split into the three parts\n",
    "        if len(cols) != 2:\n",
    "            warn = True\n",
    "        else:\n",
    "            reference.references.append((cols[0].rstrip(\";\"), cols[1].rstrip(\".\")))\n",
    "    if warn:\n",
    "        import warnings\n",
    "        from Bio import BiopythonParserWarning\n",
    "\n",
    "        warnings.warn(\"Possibly corrupt RX line %r\" % value, BiopythonParserWarning)\n",
    "\n",
    "\n",
    "def _read_cc(record, line):\n",
    "    key, value = line[5:8], line[9:].rstrip()\n",
    "    if key == \"-!-\":  # Make a new comment\n",
    "        record.comments.append(value)\n",
    "    elif key == \"   \":  # add to the previous comment\n",
    "        if not record.comments:\n",
    "            # TCMO_STRGA in Release 37 has comment with no topic\n",
    "            record.comments.append(value)\n",
    "        else:\n",
    "            record.comments[-1] += \" \" + value\n",
    "\n",
    "\n",
    "def _read_dr(record, value):\n",
    "    cols = value.rstrip(\".\").split(\"; \")\n",
    "    record.cross_references.append(tuple(cols))\n",
    "\n",
    "\n",
    "def _read_pe(record, value):\n",
    "    pe = value.split(\":\")\n",
    "    record.protein_existence = int(pe[0])\n",
    "\n",
    "\n",
    "def _read_kw(record, value):\n",
    "    # Old style - semi-colon separated, multi-line. e.g. Q13639.txt\n",
    "    # KW   Alternative splicing; Cell membrane; Complete proteome;\n",
    "    # KW   Disulfide bond; Endosome; G-protein coupled receptor; Glycoprotein;\n",
    "    # KW   Lipoprotein; Membrane; Palmitate; Polymorphism; Receptor; Transducer;\n",
    "    # KW   Transmembrane.\n",
    "    #\n",
    "    # New style as of 2014-10-01 release with evidence codes, e.g. H2CNN8.txt\n",
    "    # KW   Monooxygenase {ECO:0000313|EMBL:AEX14553.1};\n",
    "    # KW   Oxidoreductase {ECO:0000313|EMBL:AEX14553.1}.\n",
    "    # For now to match the XML parser, drop the evidence codes.\n",
    "    for value in value.rstrip(\";.\").split(\"; \"):\n",
    "        if value.endswith(\"}\"):\n",
    "            # Discard the evidence code\n",
    "            value = value.rsplit(\"{\", 1)[0]\n",
    "        record.keywords.append(value.strip())\n",
    "\n",
    "\n",
    "def _read_ft(record, line):\n",
    "    name = line[5:13].rstrip()\n",
    "    if name:\n",
    "        if line[13:21] == \"        \":  # new-style FT line\n",
    "            location = line[21:80].rstrip()\n",
    "            try:\n",
    "                isoform_id, location = location.split(\":\")\n",
    "            except ValueError:\n",
    "                isoform_id = None\n",
    "            try:\n",
    "                from_res, to_res = location.split(\"..\")\n",
    "            except ValueError:\n",
    "                from_res = location\n",
    "                to_res = \"\"\n",
    "            qualifiers = {}\n",
    "        else:  # old-style FT line\n",
    "            from_res = line[14:20].lstrip()\n",
    "            to_res = line[21:27].lstrip()\n",
    "            isoform_id = None\n",
    "            description = line[34:75].rstrip()\n",
    "            qualifiers = {\"description\": description}\n",
    "        if from_res == \"?\":\n",
    "            from_res = UnknownPosition()\n",
    "        elif from_res.startswith(\"?\"):\n",
    "            position = int(from_res[1:]) - 1  # Python zero-based counting\n",
    "            from_res = UncertainPosition(position)\n",
    "        elif from_res.startswith(\"<\"):\n",
    "            position = int(from_res[1:]) - 1  # Python zero-based counting\n",
    "            from_res = BeforePosition(position)\n",
    "        else:\n",
    "            position = int(from_res) - 1  # Python zero-based counting\n",
    "            from_res = ExactPosition(position)\n",
    "        if to_res == \"\":\n",
    "            position = from_res + 1\n",
    "            to_res = ExactPosition(position)\n",
    "        elif to_res == \"?\":\n",
    "            to_res = UnknownPosition()\n",
    "        elif to_res.startswith(\"?\"):\n",
    "            position = int(to_res[1:])\n",
    "            to_res = UncertainPosition(position)\n",
    "        elif to_res.startswith(\">\"):\n",
    "            position = int(to_res[1:])\n",
    "            to_res = AfterPosition(position)\n",
    "        else:\n",
    "            position = int(to_res)\n",
    "            to_res = ExactPosition(position)\n",
    "        location = FeatureLocation(from_res, to_res, ref=isoform_id)\n",
    "        feature = FeatureTable(\n",
    "            location=location, type=name, id=None, qualifiers=qualifiers\n",
    "        )\n",
    "        record.features.append(feature)\n",
    "        return\n",
    "    # this line is a continuation of the previous feature\n",
    "    feature = record.features[-1]\n",
    "    if line[5:34] == \"                             \":  # old-style FT line\n",
    "        description = line[34:75].rstrip()\n",
    "        if description.startswith(\"/FTId=\"):\n",
    "            # store the FTId as the feature ID\n",
    "            feature.id = description[6:].rstrip(\".\")\n",
    "            return\n",
    "        # this line is a continuation of the description of the previous feature\n",
    "        old_description = feature.qualifiers[\"description\"]\n",
    "        if old_description.endswith(\"-\"):\n",
    "            description = \"%s%s\" % (old_description, description)\n",
    "        else:\n",
    "            description = \"%s %s\" % (old_description, description)\n",
    "\n",
    "        if feature.type in (\"VARSPLIC\", \"VAR_SEQ\"):  # special case\n",
    "            # Remove unwanted spaces in sequences.\n",
    "            # During line carryover, the sequences in VARSPLIC/VAR_SEQ can get\n",
    "            # mangled with unwanted spaces like:\n",
    "            # 'DISSTKLQALPSHGLESIQT -> PCRATGWSPFRRSSPC LPTH'\n",
    "            # We want to check for this case and correct it as it happens.\n",
    "            try:\n",
    "                first_seq, second_seq = description.split(\" -> \")\n",
    "            except ValueError:\n",
    "                pass\n",
    "            else:\n",
    "                extra_info = \"\"\n",
    "                # we might have more information at the end of the\n",
    "                # second sequence, which should be in parenthesis\n",
    "                extra_info_pos = second_seq.find(\" (\")\n",
    "                if extra_info_pos != -1:\n",
    "                    extra_info = second_seq[extra_info_pos:]\n",
    "                    second_seq = second_seq[:extra_info_pos]\n",
    "                # now clean spaces out of the first and second string\n",
    "                first_seq = first_seq.replace(\" \", \"\")\n",
    "                second_seq = second_seq.replace(\" \", \"\")\n",
    "                # reassemble the description\n",
    "                description = first_seq + \" -> \" + second_seq + extra_info\n",
    "        feature.qualifiers[\"description\"] = description\n",
    "    else:  # new-style FT line\n",
    "        value = line[21:].rstrip()\n",
    "        if value.startswith(\"/id=\"):\n",
    "            qualifier_type = \"id\"\n",
    "            value = value[4:]\n",
    "            assert value.startswith('\"')\n",
    "            assert value.endswith('\"')\n",
    "            feature.id = value[1:-1]\n",
    "            return\n",
    "        elif value.startswith(\"/evidence=\"):\n",
    "            value = value[10:]\n",
    "            assert value.startswith('\"')\n",
    "            if value.endswith('\"'):\n",
    "                value = value[1:-1]\n",
    "            else:  # continues on the next line\n",
    "                value = value[1:]\n",
    "            assert \"evidence\" not in feature.qualifiers\n",
    "            feature.qualifiers[\"evidence\"] = value\n",
    "            return\n",
    "        elif value.startswith(\"/note=\"):\n",
    "            value = value[6:]\n",
    "            assert value.startswith('\"')\n",
    "            if value.endswith('\"'):\n",
    "                value = value[1:-1]\n",
    "            else:  # continues on the next line\n",
    "                value = value[1:]\n",
    "            assert \"note\" not in feature.qualifiers\n",
    "            feature.qualifiers[\"note\"] = value\n",
    "            return\n",
    "        # this line is a continuation of the description of the previous feature\n",
    "        keys = list(feature.qualifiers.keys())\n",
    "        key = keys[-1]\n",
    "        description = value.rstrip('\"')\n",
    "        old_description = feature.qualifiers[key]\n",
    "        if key == \"evidence\" or old_description.endswith(\"-\"):\n",
    "            description = \"%s%s\" % (old_description, description)\n",
    "        else:\n",
    "            description = \"%s %s\" % (old_description, description)\n",
    "        if feature.type == \"VAR_SEQ\":  # see VARSPLIC above\n",
    "            try:\n",
    "                first_seq, second_seq = description.split(\" -> \")\n",
    "            except ValueError:\n",
    "                pass\n",
    "            else:\n",
    "                extra_info = \"\"\n",
    "                # we might have more information at the end of the\n",
    "                # second sequence, which should be in parenthesis\n",
    "                extra_info_pos = second_seq.find(\" (\")\n",
    "                if extra_info_pos != -1:\n",
    "                    extra_info = second_seq[extra_info_pos:]\n",
    "                    second_seq = second_seq[:extra_info_pos]\n",
    "                # now clean spaces out of the first and second string\n",
    "                first_seq = first_seq.replace(\" \", \"\")\n",
    "                second_seq = second_seq.replace(\" \", \"\")\n",
    "                # reassemble the description\n",
    "                description = first_seq + \" -> \" + second_seq + extra_info\n",
    "        feature.qualifiers[key] = description\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHS3_BROFI\n",
      "O23729\n",
      "['Acyltransferase', 'Flavonoid biosynthesis', 'Transferase']\n",
      "'Bromheadia finlaysoniana (Orchid).'\n",
      "MAPAMEEIRQAQRAEGPAAV \n",
      "\n",
      "CHS4_BROFI\n",
      "O23730\n",
      "['Acyltransferase', 'Flavonoid biosynthesis', 'Transferase']\n",
      "'Bromheadia finlaysoniana (Orchid).'\n",
      "MAPAMEEIRQAQRAEGPAAV \n",
      "\n",
      "CHS8_BROFI\n",
      "O23731\n",
      "['Acyltransferase', 'Flavonoid biosynthesis', 'Transferase']\n",
      "'Bromheadia finlaysoniana (Orchid).'\n",
      "MAPAMEEIRQAQRAEGPAAV \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from Bio import ExPASy,SwissProt\n",
    "\n",
    "accession_nos = [\"O23729\", \"O23730\", \"O23731\"]\n",
    "handles  = [ExPASy.get_sprot_raw(a) for a in accession_nos]\n",
    "records = [read(h) for h in handles]\n",
    "for record in records:\n",
    "    print(record.entry_name)\n",
    "    print(\",\".join(record.accessions))\n",
    "    print(record.keywords)\n",
    "    print(repr(record.organism))\n",
    "    print(record.sequence[:20],\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
